{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch installation\n",
    "```\n",
    "pip install torch torchvision --index-url=download.pytoch.org/whl/cu126\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some imports\n",
    "import torch\n",
    "from ultralytics import YOLO, settings\n",
    "from PIL import Image\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cuda settings\n",
    "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# ultralytics settings\n",
    "settings.update({'datasets_dir': './datasets/CCPD'})\n",
    "settings.update({'runs_dir': './runs'})\n",
    "settings.update({'weights_dir': './weights'})\n",
    "\n",
    "# CCPD settings\n",
    "provinces = [\"皖\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\", \"苏\", \"浙\", \"京\", \"闽\", \"赣\", \"鲁\", \"豫\", \"鄂\", \"湘\", \"粤\", \"桂\", \"琼\", \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\", \"新\", \"警\", \"学\", \"O\"]\n",
    "alphabets = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W','X', 'Y', 'Z', 'O']\n",
    "ads = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'O']\n",
    "val_file_list='./datasets/CCPD/splits/val.txt'\n",
    "datasets_root_dir=Path('./datasets/CCPD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy files into CCPD/ccpd_val\\\n",
    "# import shutil\n",
    "# with open(datasets_root_dir / 'splits/val.txt', 'r') as f:\n",
    "#     for line in f.readlines():\n",
    "#         line = line.strip()\n",
    "#         shutil.copyfile(datasets_root_dir / line, datasets_root_dir / 'ccpd_val/' / line.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path, WindowsPath\n",
    "# CCPD dataloader\n",
    "class CCPDLoader:\n",
    "    def __init__(self, img_dir: str, img_size: int=640):\n",
    "        self.img_files = list(Path(img_dir).glob(\"*.jpg\"))\n",
    "        self.img_size = img_size\n",
    "        # CCPD annotation is it's filename\n",
    "        self.annotations = [self.parse_filename(f) for f in self.img_files]\n",
    "        \n",
    "    def parse_filename(self, filename: WindowsPath):\n",
    "        \"\"\"\n",
    "        Parse CCPD filename format:\n",
    "        [Area]-[Tilt Angle]-[Bounding box coordinates]-[Four vertices locations]-[License plate number]-[Brightness]-[Blurriness].jpg\n",
    "        Example: 025-95_113-154&383_386&473-386&473_177&454_154&383_363&402-0_0_22_27_27_33_16-37-15.jpg\n",
    "        \"\"\"\n",
    "        parts = filename.stem.split('-')\n",
    "        coords = list(map(int, parts[2].replace('&', ',').split(',')))\n",
    "        points = np.array(coords, dtype=np.float32).reshape(4, 2)\n",
    "        return {'points': points, 'plate_number': parts[-3]}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = cv2.imread(str(self.img_files[index]))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        # resize with same aspect ratio\n",
    "        r = min(self.img_size / h, self.img_size / w)\n",
    "        new_h, new_w = int(h * r), int(w * r)\n",
    "        img = cv2.resize(img, (new_w, new_h))\n",
    "        img = np.ascontiguousarray(img)\n",
    "        return img, self.annotations[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccpd_base/0384159482759-87_93-367&427_654&550-656&527_369&554_379&441_666&414-0_0_13_19_33_27_24-95-81.jpg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filename=list(Path('./datasets/CCPD/ccpd_base').glob('*.jpg'))[0]\n",
    "# parts=filename.stem.split('-')\n",
    "# parts[-3]\n",
    "# filename=\"025-95_113-154&383_386&473-386&473_177&454_154&383_363&402-0_0_22_27_27_33_16-37-15.jpg\"\n",
    "# filename.split('-')\n",
    "with open(val_file_list,'r') as f:\n",
    "    filename=f.readlines()\n",
    "print(filename[1])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
